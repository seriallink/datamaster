# üöÄ Como Usar o Data Master CLI

Este guia apresenta os principais comandos e fluxos de uso do **Data Master CLI**, a ferramenta central para provisionamento, simula√ß√£o, processamento e gest√£o de dados no projeto Data Master.

---

## üßë‚Äçüíª Sess√£o Interativa

Para come√ßar, basta digitar:

```bash
datamaster
````

A sess√£o interativa guiar√° voc√™ por:

1. Autentica√ß√£o via AWS Profile ou Access Key
2. Verifica√ß√£o de identidade com `whoami`
3. Fluxo guiado com op√ß√µes como:

    * [x] Deploy de infraestrutura
    * [x] Simula√ß√£o de dados (`stream`)
    * [x] Execu√ß√£o do pipeline de processamento (`processing`)
    * [x] Gerenciamento de tabelas no Glue Catalog (`catalog`)

> üí° A sess√£o mant√©m vari√°veis de ambiente ativas e permite comandos encadeados.

---

## üîß Comandos Diretos

Voc√™ tamb√©m pode usar o CLI fora da sess√£o interativa, com comandos diretos.

### 1. Deploy

Provisiona toda a infraestrutura do projeto (buckets, roles, Glue, Lambda, DMS, etc):

```bash
datamaster deploy
```

> Requer permiss√µes `AdministratorAccess` na conta AWS.

---

### 2. Stream

Simula eventos de inser√ß√£o em tabelas do Aurora para testar o pipeline de streaming:

```bash
datamaster stream --table customer --count 100
```

Par√¢metros:

* `--table`: nome da tabela a ser simulada
* `--count`: n√∫mero de eventos a gerar

---

### 3. Processing

Executa o processamento de arquivos `.gz` no bucket `dm-stage` e grava Parquet no `dm-datalake`.

```bash
datamaster processing --layer bronze --table customer
```

Tamb√©m √© poss√≠vel processar um arquivo espec√≠fico:

```bash
datamaster processing --object raw/customer/file-2025-06-01.json.gz
```

---

### 4. Catalog

Cria ou atualiza tabelas no Glue Catalog com base no schema do Aurora:

```bash
datamaster catalog
```

Ou para atualizar apenas uma camada ou tabela espec√≠fica:

```bash
datamaster catalog --layer silver --tables order_items,products
```

---

## ‚úÖ Dicas Gerais

* Use `--help` em qualquer comando para ver op√ß√µes dispon√≠veis:

```bash
datamaster processing --help
```

* Todos os comandos respeitam o ambiente (`--env`) e n√≠vel de log (`--loglevel`).

---

## üß™ Fluxo sugerido para testes

1. Execute `datamaster` e autentique-se
2. Fa√ßa o deploy da infraestrutura
3. Simule dados com `stream`
4. Verifique os arquivos `.gz` no bucket `dm-stage`
5. Execute `processing` para gerar os Parquets
6. Confirme a presen√ßa dos dados no `dm-datalake`

---

Se desejar, podemos agora expandir com:

* Sess√µes avan√ßadas (ex: comandos para debug ou integra√ß√£o com Step Functions)
* Comportamento detalhado de logs
* Lista de erros comuns e como resolv√™-los

Deseja que eu crie o arquivo `how-to-use.md` com esse conte√∫do e envie como resposta completa?
